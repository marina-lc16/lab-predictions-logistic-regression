{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d248369",
   "metadata": {},
   "source": [
    "# lab-predictions-logistic-regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71be10",
   "metadata": {},
   "source": [
    "In this lab, you will be using the Sakila database of movie rentals.\n",
    "\n",
    "In order to optimize our inventory, we would like to know which films will be rented. We are asked to create a model to predict it. So we use the information we have from May 2005 to create the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7b2a9",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f24fa0e",
   "metadata": {},
   "source": [
    "1.- Create a query or queries to extract the information you think may be relevant for building the prediction model. It should include some film features and some rental features (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917ecbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import getpass  # To get the password without showing the input\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "591577ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = 'mysql+pymysql://root:' + password + '@localhost/sakila'\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5574b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>release_year</th>\n",
       "      <th>language_id</th>\n",
       "      <th>original_language_id</th>\n",
       "      <th>rental_duration</th>\n",
       "      <th>rental_rate</th>\n",
       "      <th>length</th>\n",
       "      <th>replacement_cost</th>\n",
       "      <th>rating</th>\n",
       "      <th>special_features</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "      <td>A Epic Drama of a Feminist And a Mad Scientist...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>86</td>\n",
       "      <td>20.99</td>\n",
       "      <td>PG</td>\n",
       "      <td>{Deleted Scenes, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ACE GOLDFINGER</td>\n",
       "      <td>A Astounding Epistle of a Database Administrat...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>4.99</td>\n",
       "      <td>48</td>\n",
       "      <td>12.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Trailers, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ADAPTATION HOLES</td>\n",
       "      <td>A Astounding Reflection of a Lumberjack And a ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>2.99</td>\n",
       "      <td>50</td>\n",
       "      <td>18.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Trailers, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AFFAIR PREJUDICE</td>\n",
       "      <td>A Fanciful Documentary of a Frisbee And a Lumb...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>117</td>\n",
       "      <td>26.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Commentaries, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AFRICAN EGG</td>\n",
       "      <td>A Fast-Paced Documentary of a Pastry Chef And ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>2.99</td>\n",
       "      <td>130</td>\n",
       "      <td>22.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>AGENT TRUMAN</td>\n",
       "      <td>A Intrepid Panorama of a Robot And a Boy who m...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2.99</td>\n",
       "      <td>169</td>\n",
       "      <td>17.99</td>\n",
       "      <td>PG</td>\n",
       "      <td>{Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>AIRPLANE SIERRA</td>\n",
       "      <td>A Touching Saga of a Hunter And a Butler who m...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>4.99</td>\n",
       "      <td>62</td>\n",
       "      <td>28.99</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>{Trailers, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>AIRPORT POLLOCK</td>\n",
       "      <td>A Epic Tale of a Moose And a Girl who must Con...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>4.99</td>\n",
       "      <td>54</td>\n",
       "      <td>15.99</td>\n",
       "      <td>R</td>\n",
       "      <td>{Trailers}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>ALABAMA DEVIL</td>\n",
       "      <td>A Thoughtful Panorama of a Database Administra...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2.99</td>\n",
       "      <td>114</td>\n",
       "      <td>21.99</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>{Trailers, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>ALADDIN CALENDAR</td>\n",
       "      <td>A Action-Packed Tale of a Man And a Lumberjack...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>4.99</td>\n",
       "      <td>63</td>\n",
       "      <td>24.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Trailers, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>ALAMO VIDEOTAPE</td>\n",
       "      <td>A Boring Epistle of a Butler And a Cat who mus...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>126</td>\n",
       "      <td>16.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Commentaries, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>ALASKA PHANTOM</td>\n",
       "      <td>A Fanciful Saga of a Hunter And a Pastry Chef ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>136</td>\n",
       "      <td>22.99</td>\n",
       "      <td>PG</td>\n",
       "      <td>{Commentaries, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>ALI FOREVER</td>\n",
       "      <td>A Action-Packed Drama of a Dentist And a Croco...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4.99</td>\n",
       "      <td>150</td>\n",
       "      <td>21.99</td>\n",
       "      <td>PG</td>\n",
       "      <td>{Deleted Scenes, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>ALICE FANTASIA</td>\n",
       "      <td>A Emotional Drama of a A Shark And a Database ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>94</td>\n",
       "      <td>23.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Trailers, Deleted Scenes, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>ALIEN CENTER</td>\n",
       "      <td>A Brilliant Drama of a Cat And a Mad Scientist...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>46</td>\n",
       "      <td>10.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Commentaries, Trailers, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>ALLEY EVOLUTION</td>\n",
       "      <td>A Fast-Paced Drama of a Robot And a Composer w...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>2.99</td>\n",
       "      <td>180</td>\n",
       "      <td>23.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Commentaries, Trailers}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>ALONE TRIP</td>\n",
       "      <td>A Fast-Paced Character Study of a Composer And...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>82</td>\n",
       "      <td>14.99</td>\n",
       "      <td>R</td>\n",
       "      <td>{Trailers, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>ALTER VICTORY</td>\n",
       "      <td>A Thoughtful Drama of a Composer And a Feminis...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>57</td>\n",
       "      <td>27.99</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>{Trailers, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>AMADEUS HOLY</td>\n",
       "      <td>A Emotional Display of a Pioneer And a Technic...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>113</td>\n",
       "      <td>20.99</td>\n",
       "      <td>PG</td>\n",
       "      <td>{Commentaries, Deleted Scenes, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>AMELIE HELLFIGHTERS</td>\n",
       "      <td>A Boring Drama of a Woman And a Squirrel who m...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>4.99</td>\n",
       "      <td>79</td>\n",
       "      <td>23.99</td>\n",
       "      <td>R</td>\n",
       "      <td>{Commentaries, Deleted Scenes, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>AMERICAN CIRCUS</td>\n",
       "      <td>A Insightful Drama of a Girl And a Astronaut w...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>4.99</td>\n",
       "      <td>129</td>\n",
       "      <td>17.99</td>\n",
       "      <td>R</td>\n",
       "      <td>{Commentaries, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>AMISTAD MIDSUMMER</td>\n",
       "      <td>A Emotional Character Study of a Dentist And a...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>2.99</td>\n",
       "      <td>85</td>\n",
       "      <td>10.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Commentaries, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>ANACONDA CONFESSIONS</td>\n",
       "      <td>A Lacklusture Display of a Dentist And a Denti...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>92</td>\n",
       "      <td>9.99</td>\n",
       "      <td>R</td>\n",
       "      <td>{Trailers, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>ANALYZE HOOSIERS</td>\n",
       "      <td>A Thoughtful Display of a Explorer And a Pastr...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>2.99</td>\n",
       "      <td>181</td>\n",
       "      <td>19.99</td>\n",
       "      <td>R</td>\n",
       "      <td>{Trailers, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>ANGELS LIFE</td>\n",
       "      <td>A Thoughtful Display of a Woman And a Astronau...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2.99</td>\n",
       "      <td>74</td>\n",
       "      <td>15.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Trailers}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>ANNIE IDENTITY</td>\n",
       "      <td>A Amazing Panorama of a Pastry Chef And a Boat...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>0.99</td>\n",
       "      <td>86</td>\n",
       "      <td>15.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Commentaries, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>ANONYMOUS HUMAN</td>\n",
       "      <td>A Amazing Reflection of a Database Administrat...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.99</td>\n",
       "      <td>179</td>\n",
       "      <td>12.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Deleted Scenes, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>ANTHEM LUKE</td>\n",
       "      <td>A Touching Panorama of a Waitress And a Woman ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>4.99</td>\n",
       "      <td>91</td>\n",
       "      <td>16.99</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>{Deleted Scenes, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>ANTITRUST TOMATOES</td>\n",
       "      <td>A Fateful Yarn of a Womanizer And a Feminist w...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>168</td>\n",
       "      <td>11.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Commentaries, Trailers, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>ANYTHING SAVANNAH</td>\n",
       "      <td>A Epic Story of a Pastry Chef And a Woman who ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>2.99</td>\n",
       "      <td>82</td>\n",
       "      <td>27.99</td>\n",
       "      <td>R</td>\n",
       "      <td>{Trailers, Deleted Scenes, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>APACHE DIVINE</td>\n",
       "      <td>A Awe-Inspiring Reflection of a Pastry Chef An...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>4.99</td>\n",
       "      <td>92</td>\n",
       "      <td>16.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Commentaries, Deleted Scenes, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>APOCALYPSE FLAMINGOS</td>\n",
       "      <td>A Astounding Story of a Dog And a Squirrel who...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>4.99</td>\n",
       "      <td>119</td>\n",
       "      <td>11.99</td>\n",
       "      <td>R</td>\n",
       "      <td>{Commentaries, Trailers}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>APOLLO TEEN</td>\n",
       "      <td>A Action-Packed Reflection of a Crocodile And ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>153</td>\n",
       "      <td>15.99</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>{Commentaries, Trailers, Deleted Scenes, Behin...</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>ARABIA DOGMA</td>\n",
       "      <td>A Touching Epistle of a Madman And a Mad Cow w...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>62</td>\n",
       "      <td>29.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Commentaries, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>ARACHNOPHOBIA ROLLERCOASTER</td>\n",
       "      <td>A Action-Packed Reflection of a Pastry Chef An...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>2.99</td>\n",
       "      <td>147</td>\n",
       "      <td>24.99</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>{Trailers, Deleted Scenes, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>ARGONAUTS TOWN</td>\n",
       "      <td>A Emotional Epistle of a Forensic Psychologist...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>0.99</td>\n",
       "      <td>127</td>\n",
       "      <td>12.99</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>{Commentaries, Trailers}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>ARIZONA BANG</td>\n",
       "      <td>A Brilliant Panorama of a Mad Scientist And a ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2.99</td>\n",
       "      <td>121</td>\n",
       "      <td>28.99</td>\n",
       "      <td>PG</td>\n",
       "      <td>{Trailers, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>ARK RIDGEMONT</td>\n",
       "      <td>A Beautiful Yarn of a Pioneer And a Monkey who...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>68</td>\n",
       "      <td>25.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Commentaries, Trailers, Deleted Scenes, Behin...</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>ARMAGEDDON LOST</td>\n",
       "      <td>A Fast-Paced Tale of a Boat And a Teacher who ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>0.99</td>\n",
       "      <td>99</td>\n",
       "      <td>10.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Trailers}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>ARMY FLINTSTONES</td>\n",
       "      <td>A Boring Saga of a Database Administrator And ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99</td>\n",
       "      <td>148</td>\n",
       "      <td>22.99</td>\n",
       "      <td>R</td>\n",
       "      <td>{Commentaries, Trailers}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>41</td>\n",
       "      <td>ARSENIC INDEPENDENCE</td>\n",
       "      <td>A Fanciful Documentary of a Mad Cow And a Woma...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>0.99</td>\n",
       "      <td>137</td>\n",
       "      <td>17.99</td>\n",
       "      <td>PG</td>\n",
       "      <td>{Trailers, Deleted Scenes, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>42</td>\n",
       "      <td>ARTIST COLDBLOODED</td>\n",
       "      <td>A Stunning Reflection of a Robot And a Moose w...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>170</td>\n",
       "      <td>10.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Trailers, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>43</td>\n",
       "      <td>ATLANTIS CAUSE</td>\n",
       "      <td>A Thrilling Yarn of a Feminist And a Hunter wh...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>2.99</td>\n",
       "      <td>170</td>\n",
       "      <td>15.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>44</td>\n",
       "      <td>ATTACKS HATE</td>\n",
       "      <td>A Fast-Paced Panorama of a Technical Writer An...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>4.99</td>\n",
       "      <td>113</td>\n",
       "      <td>21.99</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>{Trailers, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>ATTRACTION NEWTON</td>\n",
       "      <td>A Astounding Panorama of a Composer And a Fris...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>4.99</td>\n",
       "      <td>83</td>\n",
       "      <td>14.99</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>{Trailers, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>46</td>\n",
       "      <td>AUTUMN CROW</td>\n",
       "      <td>A Beautiful Tale of a Dentist And a Mad Cow wh...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>4.99</td>\n",
       "      <td>108</td>\n",
       "      <td>13.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Commentaries, Trailers, Deleted Scenes, Behin...</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>47</td>\n",
       "      <td>BABY HALL</td>\n",
       "      <td>A Boring Character Study of a A Shark And a Gi...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>4.99</td>\n",
       "      <td>153</td>\n",
       "      <td>23.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Commentaries}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>BACKLASH UNDEFEATED</td>\n",
       "      <td>A Stunning Character Study of a Mad Scientist ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>4.99</td>\n",
       "      <td>118</td>\n",
       "      <td>24.99</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>{Trailers, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>49</td>\n",
       "      <td>BADMAN DAWN</td>\n",
       "      <td>A Emotional Panorama of a Pioneer And a Compos...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>2.99</td>\n",
       "      <td>162</td>\n",
       "      <td>22.99</td>\n",
       "      <td>R</td>\n",
       "      <td>{Commentaries, Trailers, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>BAKED CLEOPATRA</td>\n",
       "      <td>A Stunning Drama of a Forensic Psychologist An...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2.99</td>\n",
       "      <td>182</td>\n",
       "      <td>20.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Commentaries, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    film_id                        title  \\\n",
       "0         1             ACADEMY DINOSAUR   \n",
       "1         2               ACE GOLDFINGER   \n",
       "2         3             ADAPTATION HOLES   \n",
       "3         4             AFFAIR PREJUDICE   \n",
       "4         5                  AFRICAN EGG   \n",
       "5         6                 AGENT TRUMAN   \n",
       "6         7              AIRPLANE SIERRA   \n",
       "7         8              AIRPORT POLLOCK   \n",
       "8         9                ALABAMA DEVIL   \n",
       "9        10             ALADDIN CALENDAR   \n",
       "10       11              ALAMO VIDEOTAPE   \n",
       "11       12               ALASKA PHANTOM   \n",
       "12       13                  ALI FOREVER   \n",
       "13       14               ALICE FANTASIA   \n",
       "14       15                 ALIEN CENTER   \n",
       "15       16              ALLEY EVOLUTION   \n",
       "16       17                   ALONE TRIP   \n",
       "17       18                ALTER VICTORY   \n",
       "18       19                 AMADEUS HOLY   \n",
       "19       20          AMELIE HELLFIGHTERS   \n",
       "20       21              AMERICAN CIRCUS   \n",
       "21       22            AMISTAD MIDSUMMER   \n",
       "22       23         ANACONDA CONFESSIONS   \n",
       "23       24             ANALYZE HOOSIERS   \n",
       "24       25                  ANGELS LIFE   \n",
       "25       26               ANNIE IDENTITY   \n",
       "26       27              ANONYMOUS HUMAN   \n",
       "27       28                  ANTHEM LUKE   \n",
       "28       29           ANTITRUST TOMATOES   \n",
       "29       30            ANYTHING SAVANNAH   \n",
       "30       31                APACHE DIVINE   \n",
       "31       32         APOCALYPSE FLAMINGOS   \n",
       "32       33                  APOLLO TEEN   \n",
       "33       34                 ARABIA DOGMA   \n",
       "34       35  ARACHNOPHOBIA ROLLERCOASTER   \n",
       "35       36               ARGONAUTS TOWN   \n",
       "36       37                 ARIZONA BANG   \n",
       "37       38                ARK RIDGEMONT   \n",
       "38       39              ARMAGEDDON LOST   \n",
       "39       40             ARMY FLINTSTONES   \n",
       "40       41         ARSENIC INDEPENDENCE   \n",
       "41       42           ARTIST COLDBLOODED   \n",
       "42       43               ATLANTIS CAUSE   \n",
       "43       44                 ATTACKS HATE   \n",
       "44       45            ATTRACTION NEWTON   \n",
       "45       46                  AUTUMN CROW   \n",
       "46       47                    BABY HALL   \n",
       "47       48          BACKLASH UNDEFEATED   \n",
       "48       49                  BADMAN DAWN   \n",
       "49       50              BAKED CLEOPATRA   \n",
       "\n",
       "                                          description  release_year  \\\n",
       "0   A Epic Drama of a Feminist And a Mad Scientist...          2006   \n",
       "1   A Astounding Epistle of a Database Administrat...          2006   \n",
       "2   A Astounding Reflection of a Lumberjack And a ...          2006   \n",
       "3   A Fanciful Documentary of a Frisbee And a Lumb...          2006   \n",
       "4   A Fast-Paced Documentary of a Pastry Chef And ...          2006   \n",
       "5   A Intrepid Panorama of a Robot And a Boy who m...          2006   \n",
       "6   A Touching Saga of a Hunter And a Butler who m...          2006   \n",
       "7   A Epic Tale of a Moose And a Girl who must Con...          2006   \n",
       "8   A Thoughtful Panorama of a Database Administra...          2006   \n",
       "9   A Action-Packed Tale of a Man And a Lumberjack...          2006   \n",
       "10  A Boring Epistle of a Butler And a Cat who mus...          2006   \n",
       "11  A Fanciful Saga of a Hunter And a Pastry Chef ...          2006   \n",
       "12  A Action-Packed Drama of a Dentist And a Croco...          2006   \n",
       "13  A Emotional Drama of a A Shark And a Database ...          2006   \n",
       "14  A Brilliant Drama of a Cat And a Mad Scientist...          2006   \n",
       "15  A Fast-Paced Drama of a Robot And a Composer w...          2006   \n",
       "16  A Fast-Paced Character Study of a Composer And...          2006   \n",
       "17  A Thoughtful Drama of a Composer And a Feminis...          2006   \n",
       "18  A Emotional Display of a Pioneer And a Technic...          2006   \n",
       "19  A Boring Drama of a Woman And a Squirrel who m...          2006   \n",
       "20  A Insightful Drama of a Girl And a Astronaut w...          2006   \n",
       "21  A Emotional Character Study of a Dentist And a...          2006   \n",
       "22  A Lacklusture Display of a Dentist And a Denti...          2006   \n",
       "23  A Thoughtful Display of a Explorer And a Pastr...          2006   \n",
       "24  A Thoughtful Display of a Woman And a Astronau...          2006   \n",
       "25  A Amazing Panorama of a Pastry Chef And a Boat...          2006   \n",
       "26  A Amazing Reflection of a Database Administrat...          2006   \n",
       "27  A Touching Panorama of a Waitress And a Woman ...          2006   \n",
       "28  A Fateful Yarn of a Womanizer And a Feminist w...          2006   \n",
       "29  A Epic Story of a Pastry Chef And a Woman who ...          2006   \n",
       "30  A Awe-Inspiring Reflection of a Pastry Chef An...          2006   \n",
       "31  A Astounding Story of a Dog And a Squirrel who...          2006   \n",
       "32  A Action-Packed Reflection of a Crocodile And ...          2006   \n",
       "33  A Touching Epistle of a Madman And a Mad Cow w...          2006   \n",
       "34  A Action-Packed Reflection of a Pastry Chef An...          2006   \n",
       "35  A Emotional Epistle of a Forensic Psychologist...          2006   \n",
       "36  A Brilliant Panorama of a Mad Scientist And a ...          2006   \n",
       "37  A Beautiful Yarn of a Pioneer And a Monkey who...          2006   \n",
       "38  A Fast-Paced Tale of a Boat And a Teacher who ...          2006   \n",
       "39  A Boring Saga of a Database Administrator And ...          2006   \n",
       "40  A Fanciful Documentary of a Mad Cow And a Woma...          2006   \n",
       "41  A Stunning Reflection of a Robot And a Moose w...          2006   \n",
       "42  A Thrilling Yarn of a Feminist And a Hunter wh...          2006   \n",
       "43  A Fast-Paced Panorama of a Technical Writer An...          2006   \n",
       "44  A Astounding Panorama of a Composer And a Fris...          2006   \n",
       "45  A Beautiful Tale of a Dentist And a Mad Cow wh...          2006   \n",
       "46  A Boring Character Study of a A Shark And a Gi...          2006   \n",
       "47  A Stunning Character Study of a Mad Scientist ...          2006   \n",
       "48  A Emotional Panorama of a Pioneer And a Compos...          2006   \n",
       "49  A Stunning Drama of a Forensic Psychologist An...          2006   \n",
       "\n",
       "    language_id original_language_id  rental_duration  rental_rate  length  \\\n",
       "0             1                 None                6         0.99      86   \n",
       "1             1                 None                3         4.99      48   \n",
       "2             1                 None                7         2.99      50   \n",
       "3             1                 None                5         2.99     117   \n",
       "4             1                 None                6         2.99     130   \n",
       "5             1                 None                3         2.99     169   \n",
       "6             1                 None                6         4.99      62   \n",
       "7             1                 None                6         4.99      54   \n",
       "8             1                 None                3         2.99     114   \n",
       "9             1                 None                6         4.99      63   \n",
       "10            1                 None                6         0.99     126   \n",
       "11            1                 None                6         0.99     136   \n",
       "12            1                 None                4         4.99     150   \n",
       "13            1                 None                6         0.99      94   \n",
       "14            1                 None                5         2.99      46   \n",
       "15            1                 None                6         2.99     180   \n",
       "16            1                 None                3         0.99      82   \n",
       "17            1                 None                6         0.99      57   \n",
       "18            1                 None                6         0.99     113   \n",
       "19            1                 None                4         4.99      79   \n",
       "20            1                 None                3         4.99     129   \n",
       "21            1                 None                6         2.99      85   \n",
       "22            1                 None                3         0.99      92   \n",
       "23            1                 None                6         2.99     181   \n",
       "24            1                 None                3         2.99      74   \n",
       "25            1                 None                3         0.99      86   \n",
       "26            1                 None                7         0.99     179   \n",
       "27            1                 None                5         4.99      91   \n",
       "28            1                 None                5         2.99     168   \n",
       "29            1                 None                4         2.99      82   \n",
       "30            1                 None                5         4.99      92   \n",
       "31            1                 None                6         4.99     119   \n",
       "32            1                 None                5         2.99     153   \n",
       "33            1                 None                6         0.99      62   \n",
       "34            1                 None                4         2.99     147   \n",
       "35            1                 None                7         0.99     127   \n",
       "36            1                 None                3         2.99     121   \n",
       "37            1                 None                6         0.99      68   \n",
       "38            1                 None                5         0.99      99   \n",
       "39            1                 None                4         0.99     148   \n",
       "40            1                 None                4         0.99     137   \n",
       "41            1                 None                5         2.99     170   \n",
       "42            1                 None                6         2.99     170   \n",
       "43            1                 None                5         4.99     113   \n",
       "44            1                 None                5         4.99      83   \n",
       "45            1                 None                3         4.99     108   \n",
       "46            1                 None                5         4.99     153   \n",
       "47            1                 None                3         4.99     118   \n",
       "48            1                 None                6         2.99     162   \n",
       "49            1                 None                3         2.99     182   \n",
       "\n",
       "    replacement_cost rating  \\\n",
       "0              20.99     PG   \n",
       "1              12.99      G   \n",
       "2              18.99  NC-17   \n",
       "3              26.99      G   \n",
       "4              22.99      G   \n",
       "5              17.99     PG   \n",
       "6              28.99  PG-13   \n",
       "7              15.99      R   \n",
       "8              21.99  PG-13   \n",
       "9              24.99  NC-17   \n",
       "10             16.99      G   \n",
       "11             22.99     PG   \n",
       "12             21.99     PG   \n",
       "13             23.99  NC-17   \n",
       "14             10.99  NC-17   \n",
       "15             23.99  NC-17   \n",
       "16             14.99      R   \n",
       "17             27.99  PG-13   \n",
       "18             20.99     PG   \n",
       "19             23.99      R   \n",
       "20             17.99      R   \n",
       "21             10.99      G   \n",
       "22              9.99      R   \n",
       "23             19.99      R   \n",
       "24             15.99      G   \n",
       "25             15.99      G   \n",
       "26             12.99  NC-17   \n",
       "27             16.99  PG-13   \n",
       "28             11.99  NC-17   \n",
       "29             27.99      R   \n",
       "30             16.99  NC-17   \n",
       "31             11.99      R   \n",
       "32             15.99  PG-13   \n",
       "33             29.99  NC-17   \n",
       "34             24.99  PG-13   \n",
       "35             12.99  PG-13   \n",
       "36             28.99     PG   \n",
       "37             25.99  NC-17   \n",
       "38             10.99      G   \n",
       "39             22.99      R   \n",
       "40             17.99     PG   \n",
       "41             10.99  NC-17   \n",
       "42             15.99      G   \n",
       "43             21.99  PG-13   \n",
       "44             14.99  PG-13   \n",
       "45             13.99      G   \n",
       "46             23.99  NC-17   \n",
       "47             24.99  PG-13   \n",
       "48             22.99      R   \n",
       "49             20.99      G   \n",
       "\n",
       "                                     special_features         last_update  \n",
       "0                 {Deleted Scenes, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "1                          {Trailers, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "2                          {Trailers, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "3                   {Commentaries, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "4                                    {Deleted Scenes} 2006-02-15 05:03:42  \n",
       "5                                    {Deleted Scenes} 2006-02-15 05:03:42  \n",
       "6                          {Trailers, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "7                                          {Trailers} 2006-02-15 05:03:42  \n",
       "8                          {Trailers, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "9                          {Trailers, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "10                  {Commentaries, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "11                     {Commentaries, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "12                {Deleted Scenes, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "13      {Trailers, Deleted Scenes, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "14        {Commentaries, Trailers, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "15                           {Commentaries, Trailers} 2006-02-15 05:03:42  \n",
       "16                      {Trailers, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "17                      {Trailers, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "18  {Commentaries, Deleted Scenes, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "19  {Commentaries, Deleted Scenes, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "20                  {Commentaries, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "21                  {Commentaries, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "22                         {Trailers, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "23                      {Trailers, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "24                                         {Trailers} 2006-02-15 05:03:42  \n",
       "25                     {Commentaries, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "26                {Deleted Scenes, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "27                {Deleted Scenes, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "28           {Commentaries, Trailers, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "29      {Trailers, Deleted Scenes, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "30  {Commentaries, Deleted Scenes, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "31                           {Commentaries, Trailers} 2006-02-15 05:03:42  \n",
       "32  {Commentaries, Trailers, Deleted Scenes, Behin... 2006-02-15 05:03:42  \n",
       "33                     {Commentaries, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "34      {Trailers, Deleted Scenes, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "35                           {Commentaries, Trailers} 2006-02-15 05:03:42  \n",
       "36                         {Trailers, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "37  {Commentaries, Trailers, Deleted Scenes, Behin... 2006-02-15 05:03:42  \n",
       "38                                         {Trailers} 2006-02-15 05:03:42  \n",
       "39                           {Commentaries, Trailers} 2006-02-15 05:03:42  \n",
       "40      {Trailers, Deleted Scenes, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "41                      {Trailers, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "42                                {Behind the Scenes} 2006-02-15 05:03:42  \n",
       "43                      {Trailers, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "44                      {Trailers, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "45  {Commentaries, Trailers, Deleted Scenes, Behin... 2006-02-15 05:03:42  \n",
       "46                                     {Commentaries} 2006-02-15 05:03:42  \n",
       "47                      {Trailers, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "48        {Commentaries, Trailers, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "49                  {Commentaries, Behind the Scenes} 2006-02-15 05:03:42  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:1627: SAWarning: Did not recognize type 'geometry' of column 'location'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inventory_id</th>\n",
       "      <th>film_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-02-15 05:09:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-02-15 05:09:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-02-15 05:09:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-02-15 05:09:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-02-15 05:09:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inventory_id  film_id  store_id         last_update\n",
       "0             1        1         1 2006-02-15 05:09:17\n",
       "1             2        1         1 2006-02-15 05:09:17\n",
       "2             3        1         1 2006-02-15 05:09:17\n",
       "3             4        1         1 2006-02-15 05:09:17\n",
       "4             5        1         2 2006-02-15 05:09:17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/anaconda3/lib/python3.11/site-packages/pandas/io/sql.py:1627: SAWarning: Did not recognize type 'geometry' of column 'location'\n",
      "  self.meta.reflect(bind=self.con, only=[table_name])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>rental_date</th>\n",
       "      <th>inventory_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>return_date</th>\n",
       "      <th>staff_id</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2005-05-24 22:53:30</td>\n",
       "      <td>367</td>\n",
       "      <td>130</td>\n",
       "      <td>2005-05-26 22:04:30</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-02-15 21:30:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2005-05-24 22:54:33</td>\n",
       "      <td>1525</td>\n",
       "      <td>459</td>\n",
       "      <td>2005-05-28 19:40:33</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-02-15 21:30:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2005-05-24 23:03:39</td>\n",
       "      <td>1711</td>\n",
       "      <td>408</td>\n",
       "      <td>2005-06-01 22:12:39</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-02-15 21:30:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2005-05-24 23:04:41</td>\n",
       "      <td>2452</td>\n",
       "      <td>333</td>\n",
       "      <td>2005-06-03 01:43:41</td>\n",
       "      <td>2</td>\n",
       "      <td>2006-02-15 21:30:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2005-05-24 23:05:21</td>\n",
       "      <td>2079</td>\n",
       "      <td>222</td>\n",
       "      <td>2005-06-02 04:33:21</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-02-15 21:30:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rental_id         rental_date  inventory_id  customer_id  \\\n",
       "0          1 2005-05-24 22:53:30           367          130   \n",
       "1          2 2005-05-24 22:54:33          1525          459   \n",
       "2          3 2005-05-24 23:03:39          1711          408   \n",
       "3          4 2005-05-24 23:04:41          2452          333   \n",
       "4          5 2005-05-24 23:05:21          2079          222   \n",
       "\n",
       "          return_date  staff_id         last_update  \n",
       "0 2005-05-26 22:04:30         1 2006-02-15 21:30:53  \n",
       "1 2005-05-28 19:40:33         1 2006-02-15 21:30:53  \n",
       "2 2005-06-01 22:12:39         1 2006-02-15 21:30:53  \n",
       "3 2005-06-03 01:43:41         2 2006-02-15 21:30:53  \n",
       "4 2005-06-02 04:33:21         1 2006-02-15 21:30:53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2006-02-15 05:07:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2006-02-15 05:07:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2006-02-15 05:07:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2006-02-15 05:07:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2006-02-15 05:07:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   film_id  category_id         last_update\n",
       "0        1            6 2006-02-15 05:07:09\n",
       "1        2           11 2006-02-15 05:07:09\n",
       "2        3            6 2006-02-15 05:07:09\n",
       "3        4           11 2006-02-15 05:07:09\n",
       "4        5            8 2006-02-15 05:07:09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>name</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Action</td>\n",
       "      <td>2006-02-15 04:46:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Animation</td>\n",
       "      <td>2006-02-15 04:46:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Children</td>\n",
       "      <td>2006-02-15 04:46:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Classics</td>\n",
       "      <td>2006-02-15 04:46:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2006-02-15 04:46:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id       name         last_update\n",
       "0            1     Action 2006-02-15 04:46:27\n",
       "1            2  Animation 2006-02-15 04:46:27\n",
       "2            3   Children 2006-02-15 04:46:27\n",
       "3            4   Classics 2006-02-15 04:46:27\n",
       "4            5     Comedy 2006-02-15 04:46:27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_film = pd.read_sql_table(\"film\", engine)\n",
    "display(data_film.head(50))\n",
    "data_inventory = pd.read_sql_table(\"inventory\", engine)\n",
    "display(data_inventory.head())\n",
    "data_rental = pd.read_sql_table(\"rental\", engine)\n",
    "display(data_rental.head())\n",
    "data_film_category = pd.read_sql_table(\"film_category\", engine)\n",
    "display(data_film_category.head())\n",
    "data_category = pd.read_sql_table(\"category\", engine)\n",
    "display(data_category.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd8dc9",
   "metadata": {},
   "source": [
    "2.- Create a query to get the list of all unique film titles and a boolean indicating if it was rented (rental_date) in May 2005. (Create new column called - 'rented_in_may'). This will be our TARGET (y) variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6094f743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `features` not found.\n"
     ]
    }
   ],
   "source": [
    "-Why do you pick the current features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06014a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sakila.rental: rental_id, rental_date, name, inventory_id, customer_id\n",
    "sakila.inventory: inventory_id, film_id\n",
    "sakila.film: film_id, title, release_year, length, rating\n",
    "sakila.category: category_id, name\n",
    "sakila.film_category: film_id, category_id\n",
    "\"\"\"\n",
    "\n",
    "query = '''\n",
    "    SELECT\n",
    "      length, release_year, language_id, rating,\n",
    "      CASE\n",
    "        WHEN EXISTS (\n",
    "          SELECT 1\n",
    "          from rental as r\n",
    "        join inventory as i\n",
    "        on r.inventory_id = i.inventory_id\n",
    "        join film as f\n",
    "        on f.film_id = i.inventory_id\n",
    "          AND MONTH(rental_date) = 5\n",
    "          AND YEAR(rental_date) = 2005\n",
    "        ) THEN TRUE\n",
    "        ELSE FALSE\n",
    "      END AS rented_in_may\n",
    "    FROM film;\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6810a2",
   "metadata": {},
   "source": [
    "3.- Read the data into a Pandas dataframe. At this point you should have 1000 rows. Number of columns depends on the number of features you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d305faea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>release_year</th>\n",
       "      <th>language_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rented_in_may</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>PG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  release_year  language_id rating  rented_in_may\n",
       "0      86          2006            1     PG              1\n",
       "1      48          2006            1      G              1\n",
       "2      50          2006            1  NC-17              1\n",
       "3     117          2006            1      G              1\n",
       "4     130          2006            1      G              1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_sql_query(query, engine)\n",
    "display(df.head())\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393b020",
   "metadata": {},
   "source": [
    "4.- Analyze extracted features (X) and transform them. You may need to encode some categorical variables, or scale numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85afd7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "592d7bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Features\n",
    "# length\n",
    "# release_year\n",
    "# language_id\n",
    "\n",
    "# Categorical Features\n",
    "# title\n",
    "# rating\n",
    "# rental_in_may"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dae343d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length           0\n",
       "release_year     0\n",
       "language_id      0\n",
       "rating           0\n",
       "rented_in_may    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look for missing data\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "933c7313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length            int64\n",
       "release_year      int64\n",
       "language_id       int64\n",
       "rating           object\n",
       "rented_in_may     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28cf25",
   "metadata": {},
   "source": [
    "### Split X/y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81c4fbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>release_year</th>\n",
       "      <th>language_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>NC-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  release_year  language_id rating\n",
       "0      86          2006            1     PG\n",
       "1      48          2006            1      G\n",
       "2      50          2006            1  NC-17\n",
       "3     117          2006            1      G\n",
       "4     130          2006            1      G"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#separate the features from the labels\n",
    "\n",
    "X = df[['length','release_year','language_id', 'rating']] # X= df.drop(\"rented_in_may\", axis=1)\n",
    "y = df['rented_in_may']\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c8235af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b301bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test and X_new have the same amount of columns.\n",
    "# We can use this information when we create the Pandas DataFram\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train, columns = X.columns, index=X_train.index)\n",
    "X_test_df  = pd.DataFrame(X_test,  columns = X.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61bd996c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train_df.select_dtypes(include = np.number) \n",
    "X_test_num  = X_test_df.select_dtypes(include = np.number)\n",
    "\n",
    "X_train_cat = X_train_df.select_dtypes('object')\n",
    "X_test_cat  = X_test_df.select_dtypes('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ea7e01",
   "metadata": {},
   "source": [
    "### NUMERICAL columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ce190e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>release_year</th>\n",
       "      <th>language_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.806207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.468208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.437456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.530795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.341769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     length  release_year  language_id\n",
       "0  0.806207           0.0          0.0\n",
       "1  1.468208           0.0          0.0\n",
       "2  0.437456           0.0          0.0\n",
       "3  0.530795           0.0          0.0\n",
       "4 -0.341769           0.0          0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "power = PowerTransformer()\n",
    "\n",
    "power.fit(X_train_num)\n",
    "\n",
    "path = \"./\"\n",
    "transformer_file_name = \"power_transfomer_num.pkl\"\n",
    "\n",
    "with open(path + transformer_file_name, \"wb\") as file:\n",
    "    pickle.dump(power, file)\n",
    "\n",
    "X_train_power = power.transform(X_train_num) # .transform() applies the transformation x_normalized will be np.array\n",
    "X_test_power  = power.transform(X_test_num) # .transform() applies the transformation x_normalized will be np.array\n",
    "\n",
    "# We create new Pandas DataFrames out of the Numpy arrays.\n",
    "X_train_power_df = pd.DataFrame(X_train_power, columns=X_train_num.columns)\n",
    "X_train_power_df = pd.DataFrame(X_test_power,  columns=X_test_num.columns)\n",
    "\n",
    "X_train_power_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a94c0b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>250.0</td>\n",
       "      <td>-0.057956</td>\n",
       "      <td>0.99664</td>\n",
       "      <td>-1.823131</td>\n",
       "      <td>-0.94014</td>\n",
       "      <td>-0.02992</td>\n",
       "      <td>0.800532</td>\n",
       "      <td>1.596608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release_year</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language_id</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count      mean      std       min      25%      50%       75%  \\\n",
       "length        250.0 -0.057956  0.99664 -1.823131 -0.94014 -0.02992  0.800532   \n",
       "release_year  250.0  0.000000  0.00000  0.000000  0.00000  0.00000  0.000000   \n",
       "language_id   250.0  0.000000  0.00000  0.000000  0.00000  0.00000  0.000000   \n",
       "\n",
       "                   max  \n",
       "length        1.596608  \n",
       "release_year  0.000000  \n",
       "language_id   0.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_power_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b44b35e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'R'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gv/v5jfzcbj47xc7cbd35jg33v00000gn/T/ipykernel_48172/821017312.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mscaler_file_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"standard_scaler_num.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \"\"\"\n\u001b[1;32m    835\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1148\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 )\n\u001b[1;32m   1150\u001b[0m             ):\n\u001b[0;32m-> 1151\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \"\"\"\n\u001b[1;32m    872\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    874\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    600\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    914\u001b[0m                         )\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 raise ValueError(\n\u001b[1;32m    920\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'R'"
     ]
    }
   ],
   "source": [
    "# Scale numerical variables\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train_df)\n",
    "\n",
    "path = \"./\"\n",
    "scaler_file_name = \"standard_scaler_num.pkl\"\n",
    "\n",
    "with open(path + scaler_file_name, \"wb\") as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "X_train_scaler = scaler.transform(X_train_df) # .transform() applies the transformation x_normalized will be np.array\n",
    "X_test_scaler  = scaler.transform(X_test_df) # .transform() applies the transformation x_normalized will be np.array\n",
    "\n",
    "# We create new Pandas DataFrames out of the Numpy arrays.\n",
    "X_train_scaler_df = pd.DataFrame(X_train_scaler, columns=X_num.columns)\n",
    "X_train_scaler_df = pd.DataFrame(X_test_scaler,  columns=X_num.columns)\n",
    "\n",
    "X_train_scaler_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45a7f4",
   "metadata": {},
   "source": [
    "### CATEGORICAL columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a0e1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb83fa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>PG-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>NC-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rating\n",
       "651      R\n",
       "492      R\n",
       "210  PG-13\n",
       "220      R\n",
       "458  NC-17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_cat = X_train.select_dtypes('object')\n",
    "X_test_cat  = X_test.select_dtypes('object')\n",
    "\n",
    "X_train_cat.head()\n",
    "display(X_train_cat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12a25c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_NC-17</th>\n",
       "      <th>rating_PG</th>\n",
       "      <th>rating_PG-13</th>\n",
       "      <th>rating_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     rating_NC-17  rating_PG  rating_PG-13  rating_R\n",
       "651           0.0        0.0           0.0       1.0\n",
       "492           0.0        0.0           0.0       1.0\n",
       "210           0.0        0.0           1.0       0.0\n",
       "220           0.0        0.0           0.0       1.0\n",
       "458           1.0        0.0           0.0       0.0\n",
       "..            ...        ...           ...       ...\n",
       "289           0.0        1.0           0.0       0.0\n",
       "109           1.0        0.0           0.0       0.0\n",
       "907           0.0        0.0           0.0       0.0\n",
       "480           0.0        1.0           0.0       0.0\n",
       "688           0.0        1.0           0.0       0.0\n",
       "\n",
       "[750 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#categories_values = [list(data[col].unique()) for col in X_train_categorical.columns]\n",
    "#levels = [ [], [], ] # color (R,G,B,Y); train(R,G,B)\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "encoder.fit(X_train_cat)\n",
    "\n",
    "X_train_cat_np = encoder.transform(X_train_cat).toarray()\n",
    "X_test_cat_np  = encoder.transform(X_test_cat).toarray()\n",
    "\n",
    "display(X_train_cat_np)\n",
    "X_train_cat_encoded = pd.DataFrame(X_train_cat_np, columns=encoder.get_feature_names_out(), \n",
    "                           index=X_train_cat.index)\n",
    "X_test_cat_encoded  = pd.DataFrame(X_test_cat_np,  columns=encoder.get_feature_names_out(),\n",
    "                          index=X_test_cat.index)\n",
    "display(X_train_cat_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6ce0348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>release_year</th>\n",
       "      <th>language_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>126</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>92</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>165</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>PG-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>100</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>74</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>NC-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>163</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>53</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>NC-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>110</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>58</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>137</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     length  release_year  language_id rating\n",
       "651     126          2006            1      R\n",
       "492      92          2006            1      R\n",
       "210     165          2006            1  PG-13\n",
       "220     100          2006            1      R\n",
       "458      74          2006            1  NC-17\n",
       "..      ...           ...          ...    ...\n",
       "289     163          2006            1     PG\n",
       "109      53          2006            1  NC-17\n",
       "907     110          2006            1      G\n",
       "480      58          2006            1     PG\n",
       "688     137          2006            1     PG\n",
       "\n",
       "[750 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>release_year</th>\n",
       "      <th>language_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>126</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>92</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>165</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>PG-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>100</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>74</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>NC-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>163</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>53</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>NC-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>110</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>58</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>137</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>750 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     length  release_year  language_id rating\n",
       "651     126          2006            1      R\n",
       "492      92          2006            1      R\n",
       "210     165          2006            1  PG-13\n",
       "220     100          2006            1      R\n",
       "458      74          2006            1  NC-17\n",
       "..      ...           ...          ...    ...\n",
       "289     163          2006            1     PG\n",
       "109      53          2006            1  NC-17\n",
       "907     110          2006            1      G\n",
       "480      58          2006            1     PG\n",
       "688     137          2006            1     PG\n",
       "\n",
       "[750 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pd.concat() \n",
    "X_train_transformed_df = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "# pd.concat()\n",
    "X_test_transformed_df = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "\n",
    "display(X_train_transformed_df)\n",
    "display(X_test_transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c4d8d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>release_year</th>\n",
       "      <th>language_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.0</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>115.864000</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>40.527136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>81.250000</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>115.000000</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>185.000000</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           length  release_year  language_id\n",
       "count  750.000000         750.0        750.0\n",
       "mean   115.864000        2006.0          1.0\n",
       "std     40.527136           0.0          0.0\n",
       "min     46.000000        2006.0          1.0\n",
       "25%     81.250000        2006.0          1.0\n",
       "50%    115.000000        2006.0          1.0\n",
       "75%    150.000000        2006.0          1.0\n",
       "max    185.000000        2006.0          1.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739c70e",
   "metadata": {},
   "source": [
    "5.- Create a logistic regression model to predict 'rented_in_may' from the cleaned data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07ed1f3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'R'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gv/v5jfzcbj47xc7cbd35jg33v00000gn/T/ipykernel_48172/687832889.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m classification = LogisticRegression(random_state=0, solver='lbfgs',\n\u001b[1;32m      4\u001b[0m                   multi_class='multinomial')\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_transformed_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1148\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 )\n\u001b[1;32m   1150\u001b[0m             ):\n\u001b[0;32m-> 1151\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1203\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         raise ValueError(\n\u001b[1;32m   1144\u001b[0m             \u001b[0;34mf\"{estimator_name} requires y to be passed, but the target y is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         )\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    914\u001b[0m                         )\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 raise ValueError(\n\u001b[1;32m    920\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'R'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classification = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                  multi_class='multinomial')\n",
    "\n",
    "classification.fit(X_train_transformed_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c0ac0ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'R'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gv/v5jfzcbj47xc7cbd35jg33v00000gn/T/ipykernel_48172/2044852712.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Now we can make predictions on the test set:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_transformed_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \"\"\"\n\u001b[1;32m    450\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \"\"\"\n\u001b[1;32m    429\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    600\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    914\u001b[0m                         )\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m                 raise ValueError(\n\u001b[1;32m    920\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m                 ) from complex_warning\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'R'"
     ]
    }
   ],
   "source": [
    "# Now we can make predictions on the test set:\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_pred = classification.predict(X_test_transformed_df)\n",
    "print(y_test_pred)\n",
    "\n",
    "print(accuracy_score(y_test,y_test_pred))\n",
    "\n",
    "classification.score(X_test_transformed_df, y_test) # Accuracy for classification models and R2 for regression mnodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0af48be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rented_in_may\n",
      "1    250\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_test.value_counts())\n",
    "# As you would notice here, there is a huge imbalance in the data among the different classes. \n",
    "# We will talk more about imbalance and how to resolve it later (tomorrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04ab7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449beb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d10320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbdfda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c048d2c",
   "metadata": {},
   "source": [
    "6.- Evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8531e3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "use \"classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93506f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d57cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
